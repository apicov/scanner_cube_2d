{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:53.607078Z",
     "start_time": "2022-05-31T01:51:50.269090Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:15:18.268647Z",
     "iopub.status.busy": "2022-05-07T11:15:18.268133Z",
     "iopub.status.idle": "2022-05-07T11:15:26.191439Z",
     "shell.execute_reply": "2022-05-07T11:15:26.190876Z"
    },
    "id": "sMitx5qSgJk1"
   },
   "outputs": [],
   "source": [
    "import base64\n",
    "import imageio\n",
    "import IPython\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import reverb\n",
    "import tempfile\n",
    "import PIL.Image\n",
    "import numpy as np\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "from tf_agents.agents.ddpg import critic_network\n",
    "from tf_agents.agents.sac import sac_agent\n",
    "from tf_agents.agents.sac import tanh_normal_projection_network\n",
    "from tf_agents.environments import suite_pybullet\n",
    "from tf_agents.metrics import py_metrics\n",
    "from tf_agents.networks import actor_distribution_network\n",
    "from tf_agents.policies import greedy_policy\n",
    "from tf_agents.policies import py_tf_eager_policy\n",
    "from tf_agents.policies import random_py_policy\n",
    "from tf_agents.replay_buffers import reverb_replay_buffer\n",
    "from tf_agents.replay_buffers import reverb_utils\n",
    "from tf_agents.train import actor\n",
    "from tf_agents.train import learner\n",
    "from tf_agents.train import triggers\n",
    "from tf_agents.train.utils import spec_utils\n",
    "from tf_agents.train.utils import strategy_utils\n",
    "from tf_agents.train.utils import train_utils\n",
    "\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "#import imp\n",
    "from scan_gym import envs\n",
    "#imp.reload(envs)\n",
    "\n",
    "seed=43\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "from utils import policy_test\n",
    "\n",
    "tempdir = tempfile.gettempdir()\n",
    "import gym\n",
    "from tf_agents.environments import suite_gym\n",
    "\n",
    "from tf_agents.environments import random_py_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.networks import encoding_network\n",
    "from tf_agents.networks import network\n",
    "from tf_agents.networks import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.utils import common as common_utils\n",
    "from tf_agents.utils import nest_utils\n",
    "tf.compat.v1.enable_v2_behavior()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:53.617574Z",
     "start_time": "2022-05-31T01:51:53.609143Z"
    }
   },
   "outputs": [],
   "source": [
    "class ActorNetworkCustom(network.Network):\n",
    "\n",
    "    def __init__(self,\n",
    "                observation_spec,\n",
    "                action_spec,\n",
    "                name='ActorNetworkCustom'):\n",
    "        \n",
    "        super(ActorNetworkCustom, self).__init__(\n",
    "            input_tensor_spec=observation_spec, state_spec=(), name=name)\n",
    "\n",
    "        # For simplicity we will only support a single action float output.\n",
    "        self._action_spec = action_spec\n",
    "        flat_action_spec = tf.nest.flatten(action_spec)\n",
    "        self._single_action_spec = flat_action_spec[0]\n",
    "\n",
    "        # Initialize the custom tf layers here:\n",
    "        self._dense1 = tf.keras.layers.Dense(64, name='Dense1')\n",
    "        self._dense2 = tf.keras.layers.Dense(64, name='Dense2')\n",
    "        initializer = tf.keras.initializers.RandomUniform(\n",
    "            minval=-0.003, maxval=0.003)\n",
    "        \n",
    "        self._action_projection_layer = tf.keras.layers.Dense(\n",
    "            flat_action_spec[0].shape.num_elements(),\n",
    "            activation=tf.keras.activations.tanh,\n",
    "            kernel_initializer=initializer,\n",
    "            name='action')\n",
    "\n",
    "    def call(self, observations, step_type=(), network_state=()):\n",
    "        # We use batch_squash here in case the observations have a time sequence component.\n",
    "        outer_rank = nest_utils.get_outer_rank(observations, self.input_tensor_spec)\n",
    "        batch_squash = utils.BatchSquash(outer_rank)\n",
    "        observations = tf.nest.map_structure(batch_squash.flatten, observations)\n",
    "\n",
    "        # Forward pass through the custom tf layers here (defined above):\n",
    "        state = self._dense1(observations)\n",
    "        state = self._dense2(state)\n",
    "        actions = self._action_projection_layer(state)\n",
    "\n",
    "        actions = common_utils.scale_to_spec(actions, self._single_action_spec)\n",
    "        actions = batch_squash.unflatten(actions)\n",
    "        return tf.nest.pack_sequence_as(self._action_spec, [actions]), network_state\n",
    "    \n",
    "    \n",
    "    \n",
    "\n",
    "class CriticNetworkCustom(network.Network):\n",
    "\n",
    "    def __init__(self,\n",
    "                observation_spec,\n",
    "                action_spec,\n",
    "                name='CriticNetworkCustom'):\n",
    "        # Invoke constructor of network.Network\n",
    "        super(CriticNetworkCustom, self).__init__(\n",
    "              input_tensor_spec=(observation_spec, action_spec), state_spec=(), name=name)\n",
    "\n",
    "        self._obs_spec = observation_spec\n",
    "        self._action_spec = action_spec\n",
    "\n",
    "        # Encoding layer concatenates state and action inputs, adds dense layer:\n",
    "        kernel_initializer = tf.keras.initializers.VarianceScaling(\n",
    "            scale=1./3., mode='fan_in', distribution='uniform')\n",
    "        \n",
    "        combiner = tf.keras.layers.Concatenate(axis=-1)\n",
    "        \n",
    "        self._encoder = encoding_network.EncodingNetwork(\n",
    "            (observation_spec, action_spec),\n",
    "            fc_layer_params=(64,),\n",
    "            preprocessing_combiner = combiner,\n",
    "            activation_fn = tf.keras.activations.relu,\n",
    "            kernel_initializer = kernel_initializer,\n",
    "            batch_squash=True)\n",
    "\n",
    "        # Initialize the custom tf layers here:\n",
    "        self._dense1 = tf.keras.layers.Dense(64, name='Dense1')\n",
    "        self._value_layer = tf.keras.layers.Dense(1,\n",
    "                                                  activation=tf.keras.activations.linear,\n",
    "                                                  name='Value') # Q-function output\n",
    "\n",
    "    def call(self, observations, step_type=(), network_state=()):\n",
    "        # Forward pass through the custom tf layers here (defined above):\n",
    "        state, network_state = self._encoder(observations, \n",
    "                                             step_type=step_type, \n",
    "                                             network_state=network_state)\n",
    "        state = self._dense1(state)\n",
    "        value = self._value_layer(state)\n",
    "\n",
    "        return tf.reshape(value,[-1]), network_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LmC0NDhdLIKY"
   },
   "source": [
    "## Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:53.623246Z",
     "start_time": "2022-05-31T01:51:53.619560Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:15:26.195506Z",
     "iopub.status.busy": "2022-05-07T11:15:26.195066Z",
     "iopub.status.idle": "2022-05-07T11:15:26.199800Z",
     "shell.execute_reply": "2022-05-07T11:15:26.199192Z"
    },
    "id": "HC1kNrOsLSIZ"
   },
   "outputs": [],
   "source": [
    "env_name = \"MinitaurBulletEnv-v0\" # @param {type:\"string\"}\n",
    "\n",
    "# Use \"num_iterations = 1e6\" for better results (2 hrs)\n",
    "# 1e5 is just so this doesn't take too long (1 hr)\n",
    "num_iterations = 10000 # @param {type:\"integer\"}\n",
    "\n",
    "initial_collect_steps = 1000 # @param {type:\"integer\"}\n",
    "collect_steps_per_iteration = 1 # @param {type:\"integer\"}\n",
    "replay_buffer_capacity = 50000 # @param {type:\"integer\"}\n",
    "\n",
    "batch_size = 16 # @param {type:\"integer\"}\n",
    "\n",
    "critic_learning_rate = 3e-4 # @param {type:\"number\"}\n",
    "actor_learning_rate = 3e-4 # @param {type:\"number\"}\n",
    "alpha_learning_rate = 3e-4 # @param {type:\"number\"}\n",
    "target_update_tau = 0.005 # @param {type:\"number\"}\n",
    "target_update_period = 1 # @param {type:\"number\"}\n",
    "gamma = 0.99 # @param {type:\"number\"}\n",
    "reward_scale_factor = 1.0 # @param {type:\"number\"}\n",
    "\n",
    "log_interval = 5000 # @param {type:\"integer\"}\n",
    "\n",
    "num_eval_episodes = 20 # @param {type:\"integer\"}\n",
    "eval_interval = 10 # @param {type:\"integer\"}\n",
    "\n",
    "policy_save_interval = 5000 # @param {type:\"integer\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:54.985580Z",
     "start_time": "2022-05-31T01:51:53.624915Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:15:26.202872Z",
     "iopub.status.busy": "2022-05-07T11:15:26.202361Z",
     "iopub.status.idle": "2022-05-07T11:15:27.321836Z",
     "shell.execute_reply": "2022-05-07T11:15:27.321087Z"
    },
    "id": "RlO7WIQHu_7D"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pico/anaconda3/envs/rl/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    }
   ],
   "source": [
    "models_path  = '/home/pico/uni/romi/scanner-gym_models_v2'\n",
    "'''train_models = ['207_2d','208_2d','209_2d', '210_2d',\n",
    "               '211_2d','212_2d','213_2d' ,'214_2d']'''\n",
    "train_models = ['209_2d'] \n",
    "n_images = 10\n",
    "continuous = True\n",
    "\n",
    "env_name = 'ScannerEnv-v1'\n",
    "\n",
    "collect_env = suite_gym.load(env_name,gym_kwargs={'models_path':models_path, 'train_models':train_models,\n",
    "                                                   'n_images':n_images, 'continuous':continuous,\n",
    "                                                   'gt_mode':True,'cube_view':'static'}) \n",
    "\n",
    "eval_env = suite_gym.load(env_name,gym_kwargs={'models_path':models_path, 'train_models':train_models,\n",
    "                                                   'n_images':n_images, 'continuous':continuous,\n",
    "                                                   'gt_mode':True,'cube_view':'static'}) \n",
    "\n",
    "tf_collect_env = tf_py_environment.TFPyEnvironment(collect_env)\n",
    "tf_eval_env = tf_py_environment.TFPyEnvironment(eval_env)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:54.990209Z",
     "start_time": "2022-05-31T01:51:54.986969Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:15:27.325707Z",
     "iopub.status.busy": "2022-05-07T11:15:27.325265Z",
     "iopub.status.idle": "2022-05-07T11:15:27.331605Z",
     "shell.execute_reply": "2022-05-07T11:15:27.330924Z"
    },
    "id": "exDv57iHfwQV"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Observation Spec:\n",
      "BoundedTensorSpec(shape=(2,), dtype=tf.float32, name='observation', minimum=array([0., 0.], dtype=float32), maximum=array([179.,   3.], dtype=float32))\n",
      "Action Spec:\n",
      "BoundedTensorSpec(shape=(1,), dtype=tf.float32, name='action', minimum=array(-1., dtype=float32), maximum=array(1., dtype=float32))\n"
     ]
    }
   ],
   "source": [
    "print('Observation Spec:')\n",
    "print(tf_collect_env.time_step_spec().observation)\n",
    "print('Action Spec:')\n",
    "print(tf_collect_env.action_spec())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:55.817039Z",
     "start_time": "2022-05-31T01:51:54.991529Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:15:27.640857Z",
     "iopub.status.busy": "2022-05-07T11:15:27.640441Z",
     "iopub.status.idle": "2022-05-07T11:15:29.199346Z",
     "shell.execute_reply": "2022-05-07T11:15:29.198854Z"
    },
    "id": "ff5ZZRZI15ds"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2022-05-31 03:51:55,798 - strategy_utils - Devices: \n",
      "[LogicalDevice(name='/device:CPU:0', device_type='CPU'), LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2022-05-31 03:51:55,813 - mirrored_strategy - Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0',)\n",
      "INFO - 2022-05-31 03:51:55,814 - strategy_utils - Devices after getting strategy:\n",
      "[LogicalDevice(name='/device:CPU:0', device_type='CPU'), LogicalDevice(name='/device:GPU:0', device_type='GPU')]\n"
     ]
    }
   ],
   "source": [
    "use_gpu = True #@param {type:\"boolean\"}\n",
    "\n",
    "strategy = strategy_utils.get_strategy(tpu=False, use_gpu=use_gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "fMn5FTs5kHvt"
   },
   "source": [
    "All variables and Agents need to be created under `strategy.scope()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:55.983050Z",
     "start_time": "2022-05-31T01:51:55.819973Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:15:29.202665Z",
     "iopub.status.busy": "2022-05-07T11:15:29.202162Z",
     "iopub.status.idle": "2022-05-07T11:15:29.223753Z",
     "shell.execute_reply": "2022-05-07T11:15:29.223225Z"
    },
    "id": "TgkdEPg_muzV"
   },
   "outputs": [],
   "source": [
    "observation_spec, action_spec, time_step_spec = (\n",
    "      spec_utils.get_tensor_specs(tf_collect_env))\n",
    "\n",
    "with strategy.scope():\n",
    "    critic_net = CriticNetworkCustom(observation_spec, action_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:55.990407Z",
     "start_time": "2022-05-31T01:51:55.984955Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:15:29.226894Z",
     "iopub.status.busy": "2022-05-07T11:15:29.226417Z",
     "iopub.status.idle": "2022-05-07T11:15:29.249107Z",
     "shell.execute_reply": "2022-05-07T11:15:29.248609Z"
    },
    "id": "TB5Y3Oub4u7f"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "   actor_net = ActorNetworkCustom(observation_spec,\n",
    "                                    action_spec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:56.002412Z",
     "start_time": "2022-05-31T01:51:55.991841Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BoundedTensorSpec(shape=(1,), dtype=tf.float32, name='action', minimum=array(-1., dtype=float32), maximum=array(1., dtype=float32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "action_spec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "z62u55hSmviJ"
   },
   "source": [
    "With these networks at hand we can now instantiate the agent.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:56.975929Z",
     "start_time": "2022-05-31T01:51:56.003812Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:15:29.252085Z",
     "iopub.status.busy": "2022-05-07T11:15:29.251740Z",
     "iopub.status.idle": "2022-05-07T11:15:29.833817Z",
     "shell.execute_reply": "2022-05-07T11:15:29.833017Z"
    },
    "id": "jbY4yrjTEyc9"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "  train_step = train_utils.create_train_step()\n",
    "\n",
    "  tf_agent = sac_agent.SacAgent(\n",
    "        time_step_spec,\n",
    "        action_spec,\n",
    "        actor_network=actor_net,\n",
    "        critic_network=critic_net,\n",
    "        actor_optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=actor_learning_rate),\n",
    "        critic_optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=critic_learning_rate),\n",
    "        alpha_optimizer=tf.keras.optimizers.Adam(\n",
    "            learning_rate=alpha_learning_rate),\n",
    "        target_update_tau=target_update_tau,\n",
    "        target_update_period=target_update_period,\n",
    "        td_errors_loss_fn=tf.math.squared_difference,\n",
    "        gamma=gamma,\n",
    "        reward_scale_factor=reward_scale_factor,\n",
    "        train_step_counter=train_step)\n",
    "\n",
    "  tf_agent.initialize()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NLva6g2jdWgr"
   },
   "source": [
    "## Replay Buffer\n",
    "\n",
    "In order to keep track of the data collected from the environment, we will use [Reverb](https://deepmind.com/research/open-source/Reverb), an efficient, extensible, and easy-to-use replay system by Deepmind. It stores experience data collected by the Actors and consumed by the Learner during training.\n",
    "\n",
    "In this tutorial, this is less important than `max_size` -- but in a distributed setting with async collection and training, you will probably want to experiment with `rate_limiters.SampleToInsertRatio`, using a samples_per_insert somewhere between 2 and 1000. For example:\n",
    "```\n",
    "rate_limiter=reverb.rate_limiters.SampleToInsertRatio(samples_per_insert=3.0, min_size_to_sample=3, error_buffer=3.0)\n",
    "```\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:56.987433Z",
     "start_time": "2022-05-31T01:51:56.977092Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:15:29.837726Z",
     "iopub.status.busy": "2022-05-07T11:15:29.837177Z",
     "iopub.status.idle": "2022-05-07T11:15:29.846287Z",
     "shell.execute_reply": "2022-05-07T11:15:29.845695Z"
    },
    "id": "vX2zGUWJGWAl"
   },
   "outputs": [],
   "source": [
    "table_name = 'uniform_table'\n",
    "table = reverb.Table(\n",
    "    table_name,\n",
    "    max_size=replay_buffer_capacity,\n",
    "    sampler=reverb.selectors.Uniform(),\n",
    "    remover=reverb.selectors.Fifo(),\n",
    "    rate_limiter=reverb.rate_limiters.MinSize(1))\n",
    "\n",
    "reverb_server = reverb.Server([table])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LRNvAnkO7JK2"
   },
   "source": [
    "The replay buffer is constructed using specs describing the tensors that are to be stored, which can be obtained from the agent using `tf_agent.collect_data_spec`.\n",
    "\n",
    "Since the SAC Agent needs both the current and next observation to compute the loss, we set `sequence_length=2`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:56.997827Z",
     "start_time": "2022-05-31T01:51:56.988819Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:15:29.849373Z",
     "iopub.status.busy": "2022-05-07T11:15:29.848858Z",
     "iopub.status.idle": "2022-05-07T11:15:29.853915Z",
     "shell.execute_reply": "2022-05-07T11:15:29.853394Z"
    },
    "id": "xVLUxyUo7HQR"
   },
   "outputs": [],
   "source": [
    "reverb_replay = reverb_replay_buffer.ReverbReplayBuffer(\n",
    "    tf_agent.collect_data_spec,\n",
    "    sequence_length=2,\n",
    "    table_name=table_name,\n",
    "    local_server=reverb_server)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "rVD5nQ9ZGo8_"
   },
   "source": [
    "Now we generate a TensorFlow dataset from the Reverb replay buffer. We will pass this to the Learner to sample experiences for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:57.271170Z",
     "start_time": "2022-05-31T01:51:56.999065Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:15:29.856779Z",
     "iopub.status.busy": "2022-05-07T11:15:29.856397Z",
     "iopub.status.idle": "2022-05-07T11:15:30.154992Z",
     "shell.execute_reply": "2022-05-07T11:15:30.154439Z"
    },
    "id": "ba7bilizt_qW"
   },
   "outputs": [],
   "source": [
    "dataset = reverb_replay.as_dataset(\n",
    "      sample_batch_size=batch_size, num_steps=2).prefetch(50)\n",
    "experience_dataset_fn = lambda: dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I0KLrEPwkn5x"
   },
   "source": [
    "## Policies\n",
    "\n",
    "In TF-Agents, policies represent the standard notion of policies in RL: given a `time_step` produce an action or a distribution over actions. The main method is `policy_step = policy.step(time_step)` where `policy_step` is a named tuple `PolicyStep(action, state, info)`.  The `policy_step.action` is the `action` to be applied to the environment, `state` represents the state for stateful (RNN) policies and `info` may contain auxiliary information such as log probabilities of the actions.\n",
    "\n",
    "Agents contain two policies:\n",
    "\n",
    "-   `agent.policy` — The main policy that is used for evaluation and deployment.\n",
    "-   `agent.collect_policy` — A second policy that is used for data collection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:57.276349Z",
     "start_time": "2022-05-31T01:51:57.272527Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:15:30.159022Z",
     "iopub.status.busy": "2022-05-07T11:15:30.158542Z",
     "iopub.status.idle": "2022-05-07T11:15:30.162448Z",
     "shell.execute_reply": "2022-05-07T11:15:30.161954Z"
    },
    "id": "yq7JE8IwFe0E"
   },
   "outputs": [],
   "source": [
    "tf_eval_policy = tf_agent.policy\n",
    "eval_policy = py_tf_eager_policy.PyTFEagerPolicy(\n",
    "  tf_eval_policy, use_tf_function=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:57.280605Z",
     "start_time": "2022-05-31T01:51:57.277621Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:15:30.165114Z",
     "iopub.status.busy": "2022-05-07T11:15:30.164664Z",
     "iopub.status.idle": "2022-05-07T11:15:30.168613Z",
     "shell.execute_reply": "2022-05-07T11:15:30.168144Z"
    },
    "id": "f_A4rZveEQzW"
   },
   "outputs": [],
   "source": [
    "tf_collect_policy = tf_agent.collect_policy\n",
    "collect_policy = py_tf_eager_policy.PyTFEagerPolicy(\n",
    "  tf_collect_policy, use_tf_function=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "azkJZ8oaF8uc"
   },
   "source": [
    "Policies can be created independently of agents. For example, use `tf_agents.policies.random_py_policy` to create a policy which will randomly select an action for each time_step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:57.285173Z",
     "start_time": "2022-05-31T01:51:57.282520Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:15:30.171361Z",
     "iopub.status.busy": "2022-05-07T11:15:30.170943Z",
     "iopub.status.idle": "2022-05-07T11:15:30.174545Z",
     "shell.execute_reply": "2022-05-07T11:15:30.173986Z"
    },
    "id": "BwY7StuMkuV4"
   },
   "outputs": [],
   "source": [
    "random_policy = random_py_policy.RandomPyPolicy(\n",
    "  collect_env.time_step_spec(), collect_env.action_spec())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "l1LMqw60Kuso"
   },
   "source": [
    "## Actors\n",
    "The actor manages interactions between a policy and an environment.\n",
    "  * The Actor components contain an instance of the environment (as `py_environment`) and a copy of the policy variables.\n",
    "  * Each Actor worker runs a sequence of data collection steps given the local values of the policy variables.\n",
    "  * Variable updates are done explicitly using the variable container client instance in the training script before calling `actor.run()`.\n",
    "  * The observed experience is written into the replay buffer in each data collection step."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XjE59ct9fU7W"
   },
   "source": [
    "As the Actors run data collection steps, they pass trajectories of (state, action, reward) to the observer, which caches and writes them to the Reverb replay system. \n",
    "\n",
    "We're storing trajectories for frames [(t0,t1) (t1,t2) (t2,t3), ...] because `stride_length=1`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:51:57.289083Z",
     "start_time": "2022-05-31T01:51:57.286782Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:15:30.177504Z",
     "iopub.status.busy": "2022-05-07T11:15:30.177064Z",
     "iopub.status.idle": "2022-05-07T11:15:30.180227Z",
     "shell.execute_reply": "2022-05-07T11:15:30.179643Z"
    },
    "id": "HbyGmdiNfNDc"
   },
   "outputs": [],
   "source": [
    "rb_observer = reverb_utils.ReverbAddTrajectoryObserver(\n",
    "  reverb_replay.py_client,\n",
    "  table_name,\n",
    "  sequence_length=2,\n",
    "  stride_length=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6yaVVC22fOcF"
   },
   "source": [
    "We create an Actor with the random policy and collect experiences to seed the replay buffer with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:52:23.657096Z",
     "start_time": "2022-05-31T01:51:57.290601Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:15:30.183108Z",
     "iopub.status.busy": "2022-05-07T11:15:30.182669Z",
     "iopub.status.idle": "2022-05-07T11:16:35.310754Z",
     "shell.execute_reply": "2022-05-07T11:16:35.310014Z"
    },
    "id": "ZGq3SY0kKwsa"
   },
   "outputs": [],
   "source": [
    "initial_collect_actor = actor.Actor(\n",
    "  collect_env,\n",
    "  random_policy,\n",
    "  train_step,\n",
    "  steps_per_run=initial_collect_steps,\n",
    "  observers=[rb_observer])\n",
    "initial_collect_actor.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6Pkg-0vZP_Ya"
   },
   "source": [
    "Instantiate an Actor with the collect policy to gather more experiences during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:52:23.712998Z",
     "start_time": "2022-05-31T01:52:23.658277Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:16:35.314975Z",
     "iopub.status.busy": "2022-05-07T11:16:35.314454Z",
     "iopub.status.idle": "2022-05-07T11:16:35.452607Z",
     "shell.execute_reply": "2022-05-07T11:16:35.452030Z"
    },
    "id": "A6ooXyk0FZ5j"
   },
   "outputs": [],
   "source": [
    "env_step_metric = py_metrics.EnvironmentSteps()\n",
    "collect_actor = actor.Actor(\n",
    "  collect_env,\n",
    "  collect_policy,\n",
    "  train_step,\n",
    "  steps_per_run=1,\n",
    "  metrics=actor.collect_metrics(10),\n",
    "  summary_dir=os.path.join(tempdir, learner.TRAIN_DIR),\n",
    "  observers=[rb_observer, env_step_metric])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FR9CZ-jfPN2T"
   },
   "source": [
    "Create an Actor which will be used to evaluate the policy during training. We pass in `actor.eval_metrics(num_eval_episodes)` to log metrics later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:52:23.762690Z",
     "start_time": "2022-05-31T01:52:23.714352Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:16:35.456195Z",
     "iopub.status.busy": "2022-05-07T11:16:35.455758Z",
     "iopub.status.idle": "2022-05-07T11:16:35.588096Z",
     "shell.execute_reply": "2022-05-07T11:16:35.587491Z"
    },
    "id": "vHY2BT5lFhgL"
   },
   "outputs": [],
   "source": [
    "eval_actor = actor.Actor(\n",
    "  eval_env,\n",
    "  eval_policy,\n",
    "  train_step,\n",
    "  episodes_per_run=num_eval_episodes,\n",
    "  metrics=actor.eval_metrics(num_eval_episodes),\n",
    "  summary_dir=os.path.join(tempdir, 'eval'),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y6eBGSYiOf83"
   },
   "source": [
    "## Learners\n",
    "The Learner component contains the agent and performs gradient step updates to the policy variables using experience data from the replay buffer. After one or more training steps, the Learner can push a new set of variable values to the variable container."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:52:24.966133Z",
     "start_time": "2022-05-31T01:52:23.764131Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:16:35.592011Z",
     "iopub.status.busy": "2022-05-07T11:16:35.591451Z",
     "iopub.status.idle": "2022-05-07T11:16:43.489020Z",
     "shell.execute_reply": "2022-05-07T11:16:43.488409Z"
    },
    "id": "gi37YicSFTfF"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2022-05-31 03:52:24,939 - common - Checkpoint available: /tmp/train/checkpoints/ckpt-100000\n"
     ]
    }
   ],
   "source": [
    "saved_model_dir = os.path.join(tempdir, learner.POLICY_SAVED_MODEL_DIR)\n",
    "\n",
    "# Triggers to save the agent's policy checkpoints.\n",
    "learning_triggers = [\n",
    "    triggers.PolicySavedModelTrigger(\n",
    "        saved_model_dir,\n",
    "        tf_agent,\n",
    "        train_step,\n",
    "        interval=policy_save_interval),\n",
    "    triggers.StepPerSecondLogTrigger(train_step, interval=1000),\n",
    "]\n",
    "\n",
    "agent_learner = learner.Learner(\n",
    "  tempdir,\n",
    "  train_step,\n",
    "  tf_agent,\n",
    "  experience_dataset_fn,\n",
    "  triggers=learning_triggers,\n",
    "  strategy=strategy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "94rCXQtbUbXv"
   },
   "source": [
    "## Metrics and Evaluation\n",
    "\n",
    "We instantiated the eval Actor with `actor.eval_metrics` above, which creates most commonly used metrics during policy evaluation:\n",
    "* Average return. The return is the sum of rewards obtained while running a policy in an environment for an episode, and we usually average this over a few episodes.\n",
    "* Average episode length.\n",
    "\n",
    "We run the Actor to generate these metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:52:30.130537Z",
     "start_time": "2022-05-31T01:52:24.969843Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:16:43.493074Z",
     "iopub.status.busy": "2022-05-07T11:16:43.492523Z",
     "iopub.status.idle": "2022-05-07T11:16:53.155712Z",
     "shell.execute_reply": "2022-05-07T11:16:53.155104Z"
    },
    "id": "83iMSHUC71RG"
   },
   "outputs": [],
   "source": [
    "def get_eval_metrics():\n",
    "  eval_actor.run()\n",
    "  results = {}\n",
    "  for metric in eval_actor.metrics:\n",
    "    results[metric.name] = metric.result()\n",
    "  return results\n",
    "\n",
    "metrics = get_eval_metrics()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T01:52:30.134318Z",
     "start_time": "2022-05-31T01:52:30.131716Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:16:53.159576Z",
     "iopub.status.busy": "2022-05-07T11:16:53.159025Z",
     "iopub.status.idle": "2022-05-07T11:16:53.163381Z",
     "shell.execute_reply": "2022-05-07T11:16:53.162755Z"
    },
    "id": "jnOMvX_eZvOW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 0: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n"
     ]
    }
   ],
   "source": [
    "def log_eval_metrics(step, metrics):\n",
    "  eval_results = (', ').join(\n",
    "      '{} = {:.6f}'.format(name, result) for name, result in metrics.items())\n",
    "  print('step = {0}: {1}'.format(step, eval_results))\n",
    "\n",
    "log_eval_metrics(0, metrics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hWWURm_rXG-f"
   },
   "source": [
    "Check out the [metrics module](https://github.com/tensorflow/agents/blob/master/tf_agents/metrics/tf_metrics.py) for other standard implementations of different metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hBc9lj9VWWtZ"
   },
   "source": [
    "## Training the agent\n",
    "\n",
    "The training loop involves both collecting data from the environment and optimizing the agent's networks. Along the way, we will occasionally evaluate the agent's policy to see how we are doing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:00:19.927671Z",
     "start_time": "2022-05-31T01:52:30.135522Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T11:16:53.166836Z",
     "iopub.status.busy": "2022-05-07T11:16:53.166374Z",
     "iopub.status.idle": "2022-05-07T12:02:21.423212Z",
     "shell.execute_reply": "2022-05-07T12:02:21.422538Z"
    },
    "id": "0pTbJ3PeyF-u"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 10: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 20: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 30: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 40: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 50: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 60: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 70: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 80: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 90: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 100: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 110: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 120: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 130: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 140: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 150: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 160: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 170: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 180: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 190: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 200: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 210: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 220: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 230: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 240: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 250: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 260: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 270: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 280: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 290: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 300: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 310: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 320: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 330: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 340: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 350: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 360: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 370: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 380: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 390: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 400: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 410: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 420: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 430: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 440: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 450: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 460: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 470: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 480: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 490: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 500: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 510: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 520: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 530: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 540: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 550: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 560: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 570: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 580: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 590: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 600: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 610: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 620: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 630: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 640: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 650: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 660: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 670: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 680: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 690: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 700: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 710: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 720: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 730: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 740: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 750: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 760: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 770: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 780: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 790: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 800: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 810: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 820: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 830: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 840: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 850: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 860: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 870: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 880: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 890: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 900: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 910: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 920: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 930: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 940: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 950: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 960: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 970: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 980: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 990: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1000: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1010: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1020: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1030: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1040: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1050: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1060: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1070: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1080: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1090: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1100: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1110: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1120: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1130: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1140: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1150: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1160: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1170: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 1180: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1190: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1200: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1210: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1220: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1230: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1240: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1250: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1260: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1270: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1280: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1290: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1300: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1310: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1320: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1330: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1340: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1350: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1360: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1370: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1380: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1390: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1400: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1410: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1420: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1430: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1440: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1450: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1460: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1470: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1480: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1490: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1500: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1510: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1520: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1530: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1540: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1550: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1560: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1570: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1580: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1590: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1600: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1610: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1620: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1630: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1640: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1650: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1660: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1670: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1680: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1690: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1700: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1710: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1720: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1730: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1740: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1750: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1760: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1770: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1780: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1790: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1800: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1810: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1820: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1830: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1840: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1850: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1860: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1870: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1880: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1890: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1900: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1910: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1920: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1930: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1940: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1950: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1960: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1970: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1980: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 1990: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2000: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2010: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2020: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2030: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2040: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2050: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2060: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2070: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2080: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2090: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2100: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2110: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2120: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2130: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2140: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2150: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2160: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2170: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2180: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2190: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2200: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2210: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2220: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2230: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2240: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2250: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2260: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2270: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2280: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2290: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2300: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2310: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2320: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2330: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 2340: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2350: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2360: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2370: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2380: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2390: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2400: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2410: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2420: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2430: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2440: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2450: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2460: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2470: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2480: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2490: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2500: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2510: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2520: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2530: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2540: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2550: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2560: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2570: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2580: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2590: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2600: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2610: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2620: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2630: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2640: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2650: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2660: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2670: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2680: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2690: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2700: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2710: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2720: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2730: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2740: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2750: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2760: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2770: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2780: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2790: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2800: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2810: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2820: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2830: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2840: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2850: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2860: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2870: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2880: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2890: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2900: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2910: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2920: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2930: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2940: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2950: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2960: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2970: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2980: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 2990: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3000: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3010: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3020: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3030: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3040: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3050: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3060: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3070: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3080: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3090: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3100: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3110: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3120: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3130: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3140: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3150: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3160: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3170: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3180: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3190: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3200: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3210: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3220: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3230: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3240: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3250: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3260: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3270: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3280: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3290: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3300: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3310: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3320: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3330: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3340: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3350: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3360: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3370: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3380: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3390: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3400: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3410: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3420: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3430: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3440: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3450: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3460: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3470: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3480: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3490: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 3500: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3510: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3520: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3530: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3540: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3550: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3560: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3570: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3580: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3590: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3600: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3610: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3620: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3630: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3640: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3650: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3660: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3670: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3680: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3690: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3700: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3710: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3720: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3730: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3740: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3750: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3760: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3770: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3780: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3790: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3800: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3810: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3820: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3830: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3840: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3850: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3860: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3870: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3880: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3890: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3900: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3910: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3920: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3930: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3940: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3950: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3960: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3970: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3980: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 3990: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4000: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4010: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4020: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4030: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4040: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4050: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4060: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4070: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4080: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4090: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4100: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4110: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4120: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4130: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4140: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4150: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4160: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4170: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4180: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4190: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4200: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4210: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4220: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4230: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4240: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4250: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4260: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4270: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4280: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4290: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4300: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4310: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4320: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4330: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4340: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4350: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4360: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4370: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4380: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4390: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4400: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4410: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4420: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4430: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4440: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4450: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4460: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4470: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4480: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4490: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4500: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4510: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4520: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4530: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4540: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4550: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4560: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4570: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4580: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4590: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4600: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4610: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4620: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4630: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4640: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4650: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 4660: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4670: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4680: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4690: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4700: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4710: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4720: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4730: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4740: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4750: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4760: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4770: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4780: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4790: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4800: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4810: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4820: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4830: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4840: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4850: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4860: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4870: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4880: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4890: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4900: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4910: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4920: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4930: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4940: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4950: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4960: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4970: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4980: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 4990: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5000: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5000: loss = -4.441775321960449step = 5010: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5020: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5030: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5040: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5050: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5060: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5070: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5080: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5090: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5100: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5110: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5120: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5130: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5140: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5150: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5160: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5170: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5180: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5190: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5200: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5210: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5220: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5230: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5240: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5250: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5260: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5270: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5280: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5290: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5300: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5310: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5320: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5330: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5340: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5350: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5360: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5370: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5380: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5390: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5400: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5410: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5420: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5430: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5440: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5450: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5460: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5470: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5480: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5490: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5500: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5510: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5520: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5530: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5540: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5550: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5560: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5570: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5580: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5590: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5600: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5610: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5620: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5630: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5640: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5650: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5660: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5670: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5680: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5690: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5700: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5710: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5720: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5730: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5740: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5750: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5760: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5770: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5780: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5790: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5800: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 5810: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5820: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5830: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5840: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5850: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5860: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5870: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5880: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5890: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5900: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5910: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5920: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5930: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5940: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5950: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5960: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5970: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5980: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 5990: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6000: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6010: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6020: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6030: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6040: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6050: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6060: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6070: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6080: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6090: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6100: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6110: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6120: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6130: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6140: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6150: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6160: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6170: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6180: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6190: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6200: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6210: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6220: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6230: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6240: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6250: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6260: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6270: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6280: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6290: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6300: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6310: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6320: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6330: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6340: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6350: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6360: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6370: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6380: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6390: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6400: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6410: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6420: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6430: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6440: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6450: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6460: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6470: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6480: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6490: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6500: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6510: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6520: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6530: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6540: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6550: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6560: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6570: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6580: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6590: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6600: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6610: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6620: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6630: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6640: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6650: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6660: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6670: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6680: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6690: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6700: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6710: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6720: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6730: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6740: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6750: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6760: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6770: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6780: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6790: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6800: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6810: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6820: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6830: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6840: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6850: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6860: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6870: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6880: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6890: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6900: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6910: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6920: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6930: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6940: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6950: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6960: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step = 6970: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6980: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 6990: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7000: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7010: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7020: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7030: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7040: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7050: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7060: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7070: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7080: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7090: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7100: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7110: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7120: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7130: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7140: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7150: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7160: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7170: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7180: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7190: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7200: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7210: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7220: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7230: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7240: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7250: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7260: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7270: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7280: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7290: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7300: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7310: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7320: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7330: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7340: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7350: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7360: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7370: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7380: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7390: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7400: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7410: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7420: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7430: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7440: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7450: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7460: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7470: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7480: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7490: AverageReturn = 1.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7500: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7510: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7520: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7530: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7540: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7550: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7560: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7570: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7580: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7590: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7600: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7610: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7620: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7630: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7640: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7650: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7660: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n",
      "step = 7670: AverageReturn = 0.000000, AverageEpisodeLength = 9.000000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [24]\u001b[0m, in \u001b[0;36m<cell line: 14>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     20\u001b[0m step \u001b[38;5;241m=\u001b[39m agent_learner\u001b[38;5;241m.\u001b[39mtrain_step_numpy\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m eval_interval \u001b[38;5;129;01mand\u001b[39;00m step \u001b[38;5;241m%\u001b[39m eval_interval \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m---> 23\u001b[0m   metrics \u001b[38;5;241m=\u001b[39m \u001b[43mget_eval_metrics\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     24\u001b[0m   log_eval_metrics(step, metrics)\n\u001b[1;32m     25\u001b[0m   returns\u001b[38;5;241m.\u001b[39mappend(metrics[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAverageReturn\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "Input \u001b[0;32mIn [22]\u001b[0m, in \u001b[0;36mget_eval_metrics\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_eval_metrics\u001b[39m():\n\u001b[0;32m----> 2\u001b[0m   \u001b[43meval_actor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m   results \u001b[38;5;241m=\u001b[39m {}\n\u001b[1;32m      4\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m metric \u001b[38;5;129;01min\u001b[39;00m eval_actor\u001b[38;5;241m.\u001b[39mmetrics:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/train/actor.py:148\u001b[0m, in \u001b[0;36mActor.run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m--> 148\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_step, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_driver\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    149\u001b[0m \u001b[43m      \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_time_step\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_policy_state\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    151\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_write_summaries \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary_interval \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m\n\u001b[1;32m    152\u001b[0m       \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_step \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_last_summary \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_summary_interval):\n\u001b[1;32m    153\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwrite_metric_summaries()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/drivers/py_driver.py:111\u001b[0m, in \u001b[0;36mPyDriver.run\u001b[0;34m(self, time_step, policy_state)\u001b[0m\n\u001b[1;32m    108\u001b[0m   policy_state \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_policy\u001b[38;5;241m.\u001b[39mget_initial_state(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39menv\u001b[38;5;241m.\u001b[39mbatch_size \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m    110\u001b[0m action_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpolicy\u001b[38;5;241m.\u001b[39maction(time_step, policy_state)\n\u001b[0;32m--> 111\u001b[0m next_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;66;03m# When using observer (for the purpose of training), only the previous\u001b[39;00m\n\u001b[1;32m    114\u001b[0m \u001b[38;5;66;03m# policy_state is useful. Therefore substitube it in the PolicyStep and\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \u001b[38;5;66;03m# consume it w/ the observer.\u001b[39;00m\n\u001b[1;32m    116\u001b[0m action_step_with_previous_state \u001b[38;5;241m=\u001b[39m action_step\u001b[38;5;241m.\u001b[39m_replace(state\u001b[38;5;241m=\u001b[39mpolicy_state)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/environments/py_environment.py:232\u001b[0m, in \u001b[0;36mPyEnvironment.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_reset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step)):\n\u001b[1;32m    230\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/environments/gym_wrapper.py:214\u001b[0m, in \u001b[0;36mGymWrapper._step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    210\u001b[0m   action \u001b[38;5;241m=\u001b[39m action\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# TODO(oars): Figure out how tuple or dict actions will be generated by the\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# agents and if we can pass them through directly to gym.\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m observation, reward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_done, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gym_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_obs_space_dtype:\n\u001b[1;32m    217\u001b[0m   observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_obs_space_dtype(observation)\n",
      "File \u001b[0;32m~/uni/romi/scanner_cube_2d_ev_reward/scan_gym/scan_gym/envs/ScannerEnv/scanner_env.py:367\u001b[0m, in \u001b[0;36mScannerEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvisited_positions\u001b[38;5;241m.\u001b[39mappend((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_theta, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcurrent_phi))\n\u001b[1;32m    366\u001b[0m \u001b[38;5;66;03m#carve in new position\u001b[39;00m\n\u001b[0;32m--> 367\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcarve\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_theta\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcurrent_phi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    368\u001b[0m vol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mspc\u001b[38;5;241m.\u001b[39mvolume\n\u001b[1;32m    370\u001b[0m \u001b[38;5;66;03m#count empty voxels of current volume\u001b[39;00m\n",
      "File \u001b[0;32m~/uni/romi/scanner_cube_2d_ev_reward/scan_gym/scan_gym/envs/ScannerEnv/space_carving.py:133\u001b[0m, in \u001b[0;36mspace_carving_rotation_2d.carve\u001b[0;34m(self, theta, phi)\u001b[0m\n\u001b[1;32m    131\u001b[0m im \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload_mask(image_idx)\n\u001b[1;32m    132\u001b[0m \u001b[38;5;66;03m#im = self.load_image(image_idx)\u001b[39;00m\n\u001b[0;32m--> 133\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mspace_carve\u001b[49m\u001b[43m(\u001b[49m\u001b[43mim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mextrinsics\u001b[49m\u001b[43m[\u001b[49m\u001b[43mextrinsics_idx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvolume \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msc\u001b[38;5;241m.\u001b[39mvalues()\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcube_view \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdynamic\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# rotate cube according to current camera position\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m#moves current position's perspective to cube position 0 so position 0\u001b[39;00m\n\u001b[1;32m    140\u001b[0m     \u001b[38;5;66;03m#in cube always shows current position's perspective\u001b[39;00m\n",
      "File \u001b[0;32m~/uni/romi/scanner_cube_2d_ev_reward/scan_gym/scan_gym/envs/ScannerEnv/space_carving.py:152\u001b[0m, in \u001b[0;36mspace_carving_rotation_2d.space_carve\u001b[0;34m(self, mask, rt)\u001b[0m\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dilation:\n\u001b[1;32m    151\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dilation):\n\u001b[0;32m--> 152\u001b[0m         mask \u001b[38;5;241m=\u001b[39m \u001b[43mbinary_dilation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msc\u001b[38;5;241m.\u001b[39mprocess_view(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mintrinsics, rot, tvec, mask)\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.8/site-packages/skimage/morphology/misc.py:39\u001b[0m, in \u001b[0;36mdefault_selem.<locals>.func_out\u001b[0;34m(image, selem, *args, **kwargs)\u001b[0m\n\u001b[1;32m     37\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m selem \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     38\u001b[0m     selem \u001b[38;5;241m=\u001b[39m _default_selem(image\u001b[38;5;241m.\u001b[39mndim)\n\u001b[0;32m---> 39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mselem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.8/site-packages/skimage/morphology/binary.py:77\u001b[0m, in \u001b[0;36mbinary_dilation\u001b[0;34m(image, selem, out)\u001b[0m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m out \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     76\u001b[0m     out \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(image\u001b[38;5;241m.\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mbool\u001b[39m)\n\u001b[0;32m---> 77\u001b[0m \u001b[43mndi\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_dilation\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mselem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.8/site-packages/scipy/ndimage/_morphology.py:517\u001b[0m, in \u001b[0;36mbinary_dilation\u001b[0;34m(input, structure, iterations, mask, output, border_value, origin, brute_force)\u001b[0m\n\u001b[1;32m    514\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m structure\u001b[38;5;241m.\u001b[39mshape[ii] \u001b[38;5;241m&\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    515\u001b[0m         origin[ii] \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 517\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_binary_erosion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43miterations\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    518\u001b[0m \u001b[43m                       \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mborder_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbrute_force\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.8/site-packages/scipy/ndimage/_morphology.py:253\u001b[0m, in \u001b[0;36m_binary_erosion\u001b[0;34m(input, structure, iterations, mask, output, border_value, origin, invert, brute_force)\u001b[0m\n\u001b[1;32m    251\u001b[0m     output \u001b[38;5;241m=\u001b[39m _ni_support\u001b[38;5;241m.\u001b[39m_get_output(output\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28minput\u001b[39m)\n\u001b[1;32m    252\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m iterations \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[0;32m--> 253\u001b[0m     \u001b[43m_nd_image\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbinary_erosion\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstructure\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    254\u001b[0m \u001b[43m                             \u001b[49m\u001b[43mborder_value\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morigin\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minvert\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcit\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    255\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m cit \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m brute_force:\n\u001b[1;32m    256\u001b[0m     changed, coordinate_list \u001b[38;5;241m=\u001b[39m _nd_image\u001b[38;5;241m.\u001b[39mbinary_erosion(\n\u001b[1;32m    257\u001b[0m         \u001b[38;5;28minput\u001b[39m, structure, mask, output,\n\u001b[1;32m    258\u001b[0m         border_value, origin, invert, cit, \u001b[38;5;241m1\u001b[39m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "#@test {\"skip\": true}\n",
    "try:\n",
    "  %%time\n",
    "except:\n",
    "  pass\n",
    "\n",
    "# Reset the train step\n",
    "tf_agent.train_step_counter.assign(0)\n",
    "\n",
    "# Evaluate the agent's policy once before training.\n",
    "avg_return = get_eval_metrics()[\"AverageReturn\"]\n",
    "returns = [avg_return]\n",
    "\n",
    "for _ in range(num_iterations):\n",
    "  # Training.\n",
    "  collect_actor.run()\n",
    "  loss_info = agent_learner.run(iterations=1)\n",
    "\n",
    "  # Evaluating.\n",
    "  step = agent_learner.train_step_numpy\n",
    "\n",
    "  if eval_interval and step % eval_interval == 0:\n",
    "    metrics = get_eval_metrics()\n",
    "    log_eval_metrics(step, metrics)\n",
    "    returns.append(metrics[\"AverageReturn\"])\n",
    "\n",
    "  if log_interval and step % log_interval == 0:\n",
    "    print('\\rstep = {0}: loss = {1}'.format(step, loss_info.loss.numpy()), end=\"\")\n",
    "\n",
    "rb_observer.close()\n",
    "reverb_server.stop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "68jNcA_TiJDq"
   },
   "source": [
    "## Visualization\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aO-LWCdbbOIC"
   },
   "source": [
    "### Plots\n",
    "\n",
    "We can plot average return vs global steps to see the performance of our agent. In `Minitaur`, the reward function is based on how far the minitaur walks in 1000 steps and penalizes the energy expenditure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:00:19.929120Z",
     "start_time": "2022-05-31T01:51:50.302Z"
    },
    "execution": {
     "iopub.execute_input": "2022-05-07T12:02:21.426880Z",
     "iopub.status.busy": "2022-05-07T12:02:21.426386Z",
     "iopub.status.idle": "2022-05-07T12:02:21.546784Z",
     "shell.execute_reply": "2022-05-07T12:02:21.546225Z"
    },
    "id": "rXKzyGt72HS8"
   },
   "outputs": [],
   "source": [
    "#@test {\"skip\": true}\n",
    "\n",
    "steps = range(0, num_iterations + 1, eval_interval)\n",
    "plt.plot(steps, returns)\n",
    "plt.ylabel('Average Return')\n",
    "plt.xlabel('Step')\n",
    "plt.ylim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-30T17:05:51.581763Z",
     "start_time": "2022-05-30T17:05:51.570975Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:00:19.930014Z",
     "start_time": "2022-05-31T01:51:50.305Z"
    }
   },
   "outputs": [],
   "source": [
    "stest = policy_test.run_episode(eval_env, tf_eval_env,tf_eval_policy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-05-31T03:00:19.930576Z",
     "start_time": "2022-05-31T01:51:50.307Z"
    }
   },
   "outputs": [],
   "source": [
    "stest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "7_SAC_minitaur_tutorial.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python [conda env:rl] *",
   "language": "python",
   "name": "conda-env-rl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
