{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "disturbed-vegetation",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T22:53:26.071375Z",
     "start_time": "2022-06-13T22:53:21.396479Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPUs:  1\n"
     ]
    }
   ],
   "source": [
    "#%reload_ext tensorboard\n",
    "import numpy as np\n",
    "import json\n",
    "import tensorflow as tf\n",
    "import os\n",
    "\n",
    "import time\n",
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import gym\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices('GPU')\n",
    "#tf.config.experimental.set_memory_growth(gpus[0], True)\n",
    "if gpus:\n",
    "  try:\n",
    "    tf.config.experimental.set_virtual_device_configuration(gpus[0], \n",
    "    [tf.config.experimental.VirtualDeviceConfiguration(memory_limit=512)])\n",
    "  except RuntimeError as e:\n",
    "    print(e)\n",
    "    \n",
    "    \n",
    "print(\"GPUs: \", len(tf.config.experimental.list_physical_devices('GPU')))\n",
    "tf.config.experimental.list_logical_devices('GPU')\n",
    "\n",
    "import tf_agents\n",
    "from tf_agents.networks import categorical_q_network\n",
    "from tf_agents.agents.categorical_dqn import categorical_dqn_agent\n",
    "from tf_agents.environments import py_environment, parallel_py_environment, batched_py_environment\n",
    "from tf_agents.environments import tf_environment\n",
    "from tf_agents.environments import tf_py_environment\n",
    "from tf_agents.environments import utils\n",
    "from tf_agents.specs import array_spec\n",
    "from tf_agents.environments import wrappers\n",
    "from tf_agents.environments import suite_gym\n",
    "from tf_agents.trajectories import time_step as ts\n",
    "from tf_agents.networks.q_network import QNetwork\n",
    "from tf_agents.agents.dqn.dqn_agent import DqnAgent\n",
    "from tf_agents.replay_buffers import tf_uniform_replay_buffer\n",
    "from tf_agents.metrics import tf_metrics\n",
    "from tf_agents.drivers.dynamic_step_driver import DynamicStepDriver\n",
    "from tf_agents.policies.random_tf_policy import RandomTFPolicy\n",
    "from tf_agents.utils.common import function, element_wise_squared_loss\n",
    "from tf_agents.eval.metric_utils import log_metrics\n",
    "from tf_agents.policies import policy_saver\n",
    "import logging\n",
    "\n",
    "import tensorflow.keras as keras\n",
    "\n",
    "tf.compat.v1.enable_v2_behavior()\n",
    "import time\n",
    "import json\n",
    "import datetime\n",
    "import copy\n",
    "import shutil\n",
    "\n",
    "#import imp\n",
    "from scan_gym import envs\n",
    "from scan_gym.envs.ScannerEnv2 import space_carving\n",
    "#imp.reload(envs)\n",
    "import csv\n",
    "\n",
    "seed=42\n",
    "tf.random.set_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "import policy_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48db6b7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T22:53:26.081384Z",
     "start_time": "2022-06-13T22:53:26.072911Z"
    }
   },
   "outputs": [],
   "source": [
    "def calculate_position(init_state,steps):\n",
    "    n_positions = 180\n",
    "    n_pos = init_state + steps\n",
    "    if n_pos>(n_positions-1):\n",
    "        n_pos -= n_positions\n",
    "    elif n_pos<0:\n",
    "        n_pos += n_positions\n",
    "    return n_pos\n",
    "\n",
    "\n",
    "def run_rnd_episode_test(env,n_images):\n",
    "    state = env.reset()\n",
    "    actions = []\n",
    "    images = []\n",
    "    rewards = []\n",
    "    images.append([env.current_theta,env.current_phi])\n",
    "    for i in range(1,n_images):\n",
    "        action = np.random.randint(env.nA)\n",
    "        actions.append(action)\n",
    "        time_step = env.step(action)\n",
    "        images.append([env.current_theta,env.current_phi])\n",
    "        rewards.append(time_step.reward)\n",
    "        if time_step.step_type == 2:\n",
    "            break\n",
    "    return actions, images, env.theta_bias, rewards, env.total_reward , env.spc.gt_compare_solid(), env.spc.volume\n",
    "\n",
    "\n",
    "\n",
    "def run_episode_test(env,tf_env,policy):\n",
    "    state = tf_env.reset()\n",
    "    time_steps = 90\n",
    "    actions = []\n",
    "    images = []\n",
    "    rewards = []\n",
    "    images.append([env.current_theta,env.current_phi])\n",
    "    for i in range(1,time_steps):\n",
    "        action_step = policy.action(state)\n",
    "        actions.append(int(action_step.action.numpy()[0]))\n",
    "        state = tf_env.step(action_step.action)\n",
    "        \n",
    "        images.append([env.current_theta,env.current_phi])\n",
    "        rewards.append(float(state.reward.numpy()[0]))\n",
    "        if state.is_last():\n",
    "            break\n",
    "    return actions, images, env.theta_bias, rewards, env.total_reward , env.spc.gt_compare_solid(), env.spc.volume\n",
    "\n",
    "\n",
    "\n",
    "def run_uniform_test(models_path,model,n_images, init_theta):\n",
    "    total_theta_positions = 180\n",
    "    images = []\n",
    "    spc = space_carving.space_carving_rotation_2d( os.path.join(models_path, model[0]),\n",
    "                        gt_mode=True, theta_bias=0,\n",
    "                        total_theta_positions=total_theta_positions,\n",
    "                        cube_view='static')\n",
    "    \n",
    "    dist = total_theta_positions//n_images\n",
    "\n",
    "    theta_count = init_theta\n",
    "    for i in range(n_images):\n",
    "        spc.carve(theta_count,0)\n",
    "        images.append([theta_count,0])\n",
    "        theta_count = calculate_position(theta_count,dist)\n",
    "        \n",
    "    gt_sim = spc.gt_compare_solid()\n",
    "    return images, gt_sim, spc.volume\n",
    "\n",
    "\n",
    "\n",
    "def run_episode_test(env,tf_env,policy):\n",
    "    state = tf_env.reset()\n",
    "    time_steps = 90\n",
    "    actions = []\n",
    "    images = []\n",
    "    rewards = []\n",
    "    images.append([env.current_theta,env.current_phi])\n",
    "    for i in range(1,time_steps):\n",
    "        action_step = policy.action(state)\n",
    "        actions.append(int(action_step.action.numpy()[0]))\n",
    "        state = tf_env.step(action_step.action)\n",
    "        \n",
    "        images.append([env.current_theta,env.current_phi])\n",
    "        rewards.append(float(state.reward.numpy()[0]))\n",
    "        if state.is_last():\n",
    "            break\n",
    "    return actions, images, env.theta_bias, rewards, env.total_reward , env.spc.gt_compare_solid(), env.spc.volume"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "29d0a434",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T22:53:26.093131Z",
     "start_time": "2022-06-13T22:53:26.082790Z"
    }
   },
   "outputs": [],
   "source": [
    "def plot_vol_cam(vol,cam_pts):\n",
    "    # for creating a responsive plot\n",
    "    %matplotlib widget\n",
    "    # importing required libraries\n",
    "    from mpl_toolkits.mplot3d import Axes3D\n",
    "    import matplotlib.pyplot as plt\n",
    "    import matplotlib.cm as cm\n",
    "\n",
    "    def plot_colourline(x,y,z,c,ax):\n",
    "        c = cm.jet((c-np.min(c))/(np.max(c)-np.min(c)))\n",
    "        for i in np.arange(len(x)-1):\n",
    "            ax.plot([x[i],x[i+1]], [y[i],y[i+1]],[z[i],z[i+1]], c=c[i])\n",
    "        return\n",
    "    \n",
    "    def minMaxNorm(old, oldmin, oldmax , newmin , newmax):\n",
    "        return ( (old-oldmin)*(newmax-newmin)/(oldmax-oldmin) ) + newmin\n",
    "    \n",
    "    \n",
    "    def a2c(angles, R=5,n_theta=180,n_phi=4):\n",
    "        theta= angles[:,0]*2*np.pi/n_theta\n",
    "        phi=angles[:,1]*.5*np.pi/n_phi\n",
    "        x = R *np.cos(phi) * np.cos(theta) #x pos of camera\n",
    "        y = R *np.cos(phi) * np.sin(theta) #y pos of camera   \n",
    "        z = R *np.sin(phi)\n",
    "        return [x,y,z]\n",
    "    \n",
    "    x,y,z = np.where(vol==1)\n",
    "    x = minMaxNorm(x,0,63,-4,4)\n",
    "    y = minMaxNorm(y,0,63,-4,4)\n",
    "    z = minMaxNorm(z,0,63,-4,4)\n",
    "\n",
    "    # creating figure\n",
    "    fig = plt.figure(figsize=(10,8))\n",
    "    ax = Axes3D(fig)\n",
    "\n",
    "    ax.set_xlim3d(-5.5, 5.5)\n",
    "    ax.set_ylim3d(-5.5, 5.5)\n",
    "    ax.set_zlim3d(-5.5, 5.5)\n",
    "\n",
    "    # creating the plot\n",
    "    p = ax.scatter(x, y, z, color='green',s=1)\n",
    "\n",
    "    #x,y,z = np.where(spc.sc.values()==0)\n",
    "    cam_pts = np.array(cam_pts)\n",
    "    crd = a2c(cam_pts)\n",
    "    ax.scatter(crd[0], crd[1], crd[2], color='red',s=20)\n",
    "    plot_colourline(crd[0], crd[1], crd[2], np.arange(len(crd[0])), ax)\n",
    "    fig.colorbar(p)\n",
    "\n",
    "    # setting title and labels\n",
    "    ax.set_title(\"3D plot\")\n",
    "    ax.set_xlabel('x-axis')\n",
    "    ax.set_ylabel('y-axis')\n",
    "    ax.set_zlabel('z-axis')\n",
    "    ax.grid()\n",
    "    \n",
    "    #make  0 origin coincide in all axis\n",
    "    ax.xaxis._axinfo['juggled'] = (0,0,0)\n",
    "    ax.yaxis._axinfo['juggled'] = (1,1,1)\n",
    "    ax.zaxis._axinfo['juggled'] = (2,2,2)\n",
    "    \n",
    "    ax.view_init(90, 0)\n",
    "\n",
    "    # displaying the plot\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ambient-bandwidth",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T22:53:26.561316Z",
     "start_time": "2022-06-13T22:53:26.094354Z"
    }
   },
   "outputs": [],
   "source": [
    "policy_name ='218_20220613-112522'\n",
    "policies_path = '/home/pico/uni/romi/policies_test'\n",
    "policy = tf.compat.v2.saved_model.load(os.path.join(policies_path,policy_name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "honest-integer",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T22:53:26.649818Z",
     "start_time": "2022-06-13T22:53:26.562622Z"
    }
   },
   "outputs": [],
   "source": [
    "models_path  = '/home/pico/uni/romi/scanner-gym_models_v2'\n",
    "models = ['207_2d','208_2d','209_2d','210_2d','211_2d']\n",
    "'''train_models = ['207_2d','208_2d','209_2d', '210_2d',\n",
    "               '211_2d','212_2d','213_2d' ,'214_2d']'''\n",
    "train_models = ['218_2d']\n",
    "n_images = 10\n",
    "continuous = False\n",
    "\n",
    "#scan_env = gym.make('ScannerEnv-v1', models_path=models_path, train_models=models,\n",
    "#                   n_images = n_images, continuous=continuous, gt_mode=True, cube_view='static')\n",
    "\n",
    "env = suite_gym.load('ScannerEnv-v2',gym_kwargs={'models_path':models_path, 'train_models':train_models,\n",
    "                                                   'n_images':n_images, 'continuous':continuous,\n",
    "                                                   'gt_mode':True,'cube_view':'static'}) \n",
    "\n",
    "tf_env =  tf_py_environment.TFPyEnvironment( env )"
   ]
  },
  {
   "cell_type": "raw",
   "id": "0fe034ad",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T18:32:47.209564Z",
     "start_time": "2022-06-13T18:31:18.562970Z"
    }
   },
   "source": [
    "# test learned policy\n",
    "'''test_models = ['206_2d','207_2d','208_2d','209_2d', '210_2d',\n",
    "               '211_2d','212_2d','213_2d' ,'214_2d' ,'215_2d',\n",
    "               '216_2d','217_2d','218_2d']'''\n",
    "test_models = ['212_2d']\n",
    "test_data = policy_name+'.json'\n",
    "policy_test.test_policy(environment='ScannerEnv-v2', models_path=models_path,\n",
    "                        models=test_models, policy=policy,\n",
    "                        n_images=n_images, n_episodes = 180, dest_path=test_data )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "neural-conflict",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T22:54:22.628545Z",
     "start_time": "2022-06-13T22:54:22.129580Z"
    }
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "142",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m actions, positions, theta_bias, rwds, t_rwd, dist_solid , vol \u001b[38;5;241m=\u001b[39m \u001b[43mrun_episode_test\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtf_env\u001b[49m\u001b[43m,\u001b[49m\u001b[43mpolicy\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(actions)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(positions)\n",
      "Input \u001b[0;32mIn [2]\u001b[0m, in \u001b[0;36mrun_episode_test\u001b[0;34m(env, tf_env, policy)\u001b[0m\n\u001b[1;32m     78\u001b[0m action_step \u001b[38;5;241m=\u001b[39m policy\u001b[38;5;241m.\u001b[39maction(state)\n\u001b[1;32m     79\u001b[0m actions\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mint\u001b[39m(action_step\u001b[38;5;241m.\u001b[39maction\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]))\n\u001b[0;32m---> 80\u001b[0m state \u001b[38;5;241m=\u001b[39m \u001b[43mtf_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction_step\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     82\u001b[0m images\u001b[38;5;241m.\u001b[39mappend([env\u001b[38;5;241m.\u001b[39mcurrent_theta,env\u001b[38;5;241m.\u001b[39mcurrent_phi])\n\u001b[1;32m     83\u001b[0m rewards\u001b[38;5;241m.\u001b[39mappend(\u001b[38;5;28mfloat\u001b[39m(state\u001b[38;5;241m.\u001b[39mreward\u001b[38;5;241m.\u001b[39mnumpy()[\u001b[38;5;241m0\u001b[39m]))\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/environments/tf_environment.py:241\u001b[0m, in \u001b[0;36mTFEnvironment.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mstep\u001b[39m(\u001b[38;5;28mself\u001b[39m, action):\n\u001b[1;32m    212\u001b[0m   \u001b[38;5;124;03m\"\"\"Steps the environment according to the action.\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \n\u001b[1;32m    214\u001b[0m \u001b[38;5;124;03m  If the environment returned a `TimeStep` with `StepType.LAST` at the\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    239\u001b[0m \u001b[38;5;124;03m        corresponding to `observation_spec()`.\u001b[39;00m\n\u001b[1;32m    240\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m--> 241\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/environments/tf_py_environment.py:315\u001b[0m, in \u001b[0;36mTFPyEnvironment._step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    309\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (action\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;241m.\u001b[39mrank \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    310\u001b[0m         (dim_value \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m dim_value \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size)):\n\u001b[1;32m    311\u001b[0m       \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m    312\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mExpected actions whose major dimension is batch_size (\u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m), \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    313\u001b[0m           \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbut saw action with shape \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m   \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m\n\u001b[1;32m    314\u001b[0m           (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbatch_size, action\u001b[38;5;241m.\u001b[39mshape, action))\n\u001b[0;32m--> 315\u001b[0m outputs \u001b[38;5;241m=\u001b[39m \u001b[43mtf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnumpy_function\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    316\u001b[0m \u001b[43m    \u001b[49m\u001b[43m_isolated_step_py\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    317\u001b[0m \u001b[43m    \u001b[49m\u001b[43mflat_actions\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    318\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_time_step_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    319\u001b[0m \u001b[43m    \u001b[49m\u001b[43mname\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mstep_py_func\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    320\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_step_from_numpy_function_outputs(outputs)\n",
      "File \u001b[0;32m~/anaconda3/envs/rl/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:153\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[0;32m--> 153\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28mNone\u001b[39m\n\u001b[1;32m    154\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    155\u001b[0m   \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/environments/tf_py_environment.py:302\u001b[0m, in \u001b[0;36mTFPyEnvironment._step.<locals>._isolated_step_py\u001b[0;34m(*flattened_actions)\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_isolated_step_py\u001b[39m(\u001b[38;5;241m*\u001b[39mflattened_actions):\n\u001b[0;32m--> 302\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_step_py\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflattened_actions\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/environments/tf_py_environment.py:211\u001b[0m, in \u001b[0;36mTFPyEnvironment._execute\u001b[0;34m(self, fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_execute\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    210\u001b[0m   \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool:\n\u001b[0;32m--> 211\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    212\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pool\u001b[38;5;241m.\u001b[39mapply(fn, args\u001b[38;5;241m=\u001b[39margs, kwds\u001b[38;5;241m=\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/environments/tf_py_environment.py:298\u001b[0m, in \u001b[0;36mTFPyEnvironment._step.<locals>._step_py\u001b[0;34m(*flattened_actions)\u001b[0m\n\u001b[1;32m    295\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m _check_not_called_concurrently(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock):\n\u001b[1;32m    296\u001b[0m   packed \u001b[38;5;241m=\u001b[39m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mpack_sequence_as(\n\u001b[1;32m    297\u001b[0m       structure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_spec(), flat_sequence\u001b[38;5;241m=\u001b[39mflattened_actions)\n\u001b[0;32m--> 298\u001b[0m   \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_env\u001b[38;5;241m.\u001b[39mstep(packed)\n\u001b[1;32m    299\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tf\u001b[38;5;241m.\u001b[39mnest\u001b[38;5;241m.\u001b[39mflatten(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time_step)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/environments/py_environment.py:232\u001b[0m, in \u001b[0;36mPyEnvironment.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_reset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step)):\n\u001b[1;32m    230\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/environments/batched_py_environment.py:165\u001b[0m, in \u001b[0;36mBatchedPyEnvironment._step\u001b[0;34m(self, actions)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_envs \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m    164\u001b[0m   actions \u001b[38;5;241m=\u001b[39m nest_utils\u001b[38;5;241m.\u001b[39munbatch_nested_array(actions)\n\u001b[0;32m--> 165\u001b[0m   time_steps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_envs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43mactions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    166\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m nest_utils\u001b[38;5;241m.\u001b[39mbatch_nested_array(time_steps)\n\u001b[1;32m    167\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/environments/py_environment.py:232\u001b[0m, in \u001b[0;36mPyEnvironment.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    228\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m    229\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshould_reset(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step)):\n\u001b[1;32m    230\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreset()\n\u001b[0;32m--> 232\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_step\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_current_time_step\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/tf_agents/environments/gym_wrapper.py:214\u001b[0m, in \u001b[0;36mGymWrapper._step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    210\u001b[0m   action \u001b[38;5;241m=\u001b[39m action\u001b[38;5;241m.\u001b[39mitem()\n\u001b[1;32m    212\u001b[0m \u001b[38;5;66;03m# TODO(oars): Figure out how tuple or dict actions will be generated by the\u001b[39;00m\n\u001b[1;32m    213\u001b[0m \u001b[38;5;66;03m# agents and if we can pass them through directly to gym.\u001b[39;00m\n\u001b[0;32m--> 214\u001b[0m observation, reward, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_done, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_info \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gym_env\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstep\u001b[49m\u001b[43m(\u001b[49m\u001b[43maction\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    216\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_match_obs_space_dtype:\n\u001b[1;32m    217\u001b[0m   observation \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_to_obs_space_dtype(observation)\n",
      "File \u001b[0;32m~/uni/romi/scanner_cube_2d/scan_gym/scan_gym/envs/ScannerEnv2/scanner_env.py:375\u001b[0m, in \u001b[0;36mScannerEnv.step\u001b[0;34m(self, action)\u001b[0m\n\u001b[1;32m    370\u001b[0m     phi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mphi_from_continuous(action[\u001b[38;5;241m1\u001b[39m])\n\u001b[1;32m    373\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    374\u001b[0m     \u001b[38;5;66;03m# decode theta and phi from action number\u001b[39;00m\n\u001b[0;32m--> 375\u001b[0m     theta \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions\u001b[49m\u001b[43m[\u001b[49m\u001b[43maction\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    376\u001b[0m     phi \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactions[action][\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    379\u001b[0m \u001b[38;5;66;03m#move n theta steps from current theta position\u001b[39;00m\n",
      "\u001b[0;31mKeyError\u001b[0m: 142"
     ]
    }
   ],
   "source": [
    "actions, positions, theta_bias, rwds, t_rwd, dist_solid , vol = run_episode_test(env,tf_env,policy)\n",
    "print(actions)\n",
    "print(positions)\n",
    "print(t_rwd)\n",
    "print(dist_solid)\n",
    "plot_vol_cam(vol,positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac272d05",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T22:47:49.528077Z",
     "start_time": "2022-06-13T22:47:49.476724Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e82788e6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T22:53:29.922163Z",
     "start_time": "2022-06-13T22:53:29.398025Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[20, 102, 121, 74, 87, 116, 99, 103, 130]\n",
      "[[106, 3], [110, 3], [143, 3], [3, 2], [26, 3], [54, 3], [91, 3], [124, 1], [157, 3], [19, 3]]\n",
      "0.6578985492249426\n",
      "0.6578985492249426\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eeca80beff12403799243ad0ef77451a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "actions, positions, theta_bias, rwds, t_rwd, dist_solid , vol = run_rnd_episode_test(env,n_images)\n",
    "print(actions)\n",
    "print(positions)\n",
    "print(t_rwd)\n",
    "print(dist_solid)\n",
    "plot_vol_cam(vol,positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e34089",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T22:47:08.283247Z",
     "start_time": "2022-06-13T22:47:08.221583Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f29110f2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T22:53:30.132307Z",
     "start_time": "2022-06-13T22:53:29.923259Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0, 0], [18, 0], [36, 0], [54, 0], [72, 0], [90, 0], [108, 0], [126, 0], [144, 0], [162, 0]]\n",
      "0.4237346876207995\n"
     ]
    }
   ],
   "source": [
    "positions , rwd, vol  = run_uniform_test(models_path,train_models,n_images, 0)\n",
    "print(positions)\n",
    "print(rwd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dd1f7cc6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-06-13T22:53:30.185705Z",
     "start_time": "2022-06-13T22:53:30.133628Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8b1e8e04cc4a478fb37e771e769dbb63",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_vol_cam(vol,positions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb1af0e2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:rl] *",
   "language": "python",
   "name": "conda-env-rl-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
